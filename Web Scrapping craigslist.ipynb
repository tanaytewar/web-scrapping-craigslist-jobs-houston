{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping Craigslist for Jobs in Houston\n",
    "# By: Tanay Tewar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define URL\n",
    "# we will be scrapping all the job titles in boston on craigslist, so search that\n",
    "url=\"https://houston.craigslist.org/d/jobs/search/jjj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get webpage, create response object\n",
    "response=requests.get(url)\n",
    "response\n",
    "# if output is \"<Response [200]>\" then all is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraact the sourse code of a webpage\n",
    "# it could be in HTML, Javascript etc\n",
    "data=response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "# this is the sourse code of the site, but is extremely unreadable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make \"data\" readable, pass the object to BeautifulSoup\n",
    "soup=BeautifulSoup(data,'html.parser')\n",
    "# after this, it appers same, but it is structured for a machine to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING ALL URLs\n",
    "# extract tags to a list\n",
    "# we will extract all 'a' tags, as <a> defines HYPERLINKS\n",
    "tags=soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will extract our url links by using 'href' in <a> tag by oopings on the \"tags \" list\n",
    "# i.e clean the links from their code\n",
    "for i in tags:\n",
    "    print(i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets scrap titles of jobs inahmedabad on craigslist\n",
    "#instead of tags, we will extract titles\n",
    "titles=soup.find_all('a',{'class':'result-title hdrlnk'})\n",
    "'''\n",
    "This {'class':'result-title hdrlnk'} is the variable set by programmer of the site for a title. \n",
    "so to see it, click on any ticle and do inspect element, and use the \" class attribute in it\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the title\n",
    "for i in titles:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will extract cities in the job tites\n",
    "cities=soup.find_all('span',{'class':'result-hood'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cities:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We extracted address and title seperately, so in case there is misssing value,it will cause mismatches.\n",
    "So, we use wrappers.\n",
    "Wrappers encase all details of a particular entity in a tag\n",
    "i.e each job is contained within a tag, called a wrapper. Here, the wrapper tag is \"p\"\n",
    "'''\n",
    "# making list of all the job wrappers\n",
    "jobs=soup.find_all(\"div\",{\"class\":\"result-info\"})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting each individual tag from wrapper\n",
    "for i in jobs:\n",
    "    # here, use find instead of find_all as need just the first occurance\n",
    "    title=i.find('a',{'class':'result-title'}).text\n",
    "    \n",
    "    loc_tag=i.find('span',{'class':'result-hood'})\n",
    "    # if location is missing, it will give error, so we handle that using if clause\n",
    "    location=loc_tag.text[2:-1] if loc_tag else 'N/A'\n",
    "    # location is displayed inside brackets, so we use slicing to remove brackets and strip to remove white spaces\n",
    "    \n",
    "    date=i.find('time',{'class':'result-date'}).text\n",
    "    link=i.find('a',{'class':'result-title'}).get('href')\n",
    "    \n",
    "    '''\n",
    "    To access job description, we need to open the page. We will use the job link like we used th emain site url,\n",
    "    and that way we can access individual pages of each job.\n",
    "    \n",
    "    We will do same process for the job url \"link\" as we did to access man page url.\n",
    "    '''\n",
    "    # connecting to job page\n",
    "    job_response=requests.get(link)\n",
    "    # get source code\n",
    "    job_data=job_response.text\n",
    "    # pass source code to beautiful soup\n",
    "    job_soup=BeautifulSoup(job_data,\"html.parser\")\n",
    "    # extracting job description\n",
    "    job_description=job_soup.find('section',{'id':'postingbody'}).text\n",
    "    # extracting optional job attribus like compensation, employment type etc\n",
    "    job_attributes_tag=job_soup.find('p',{'class','attrgroup'})\n",
    "    job_attributes=job_attributes_tag.text if job_attributes_tag else 'N/A'\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Printing\n",
    "    print('Job Title:',title,\n",
    "            '\\nLocation:',location,\n",
    "             '\\nDate:',date,\n",
    "             '\\nLink:',link,\n",
    "              '\\nJob Description:',job_description,\n",
    "              '\\nJob Attributes:',job_attributes,\n",
    "             '\\n----------------------------------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
